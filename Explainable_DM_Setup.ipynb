{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import numpy as np\n",
    "import scipy.spatial as sp\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Import pyomo environment and setup gurobi solver\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverStatus, TerminationCondition\n",
    "import gurobipy \n",
    "solver = pyo.SolverFactory(\"gurobi_direct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Instance to explain + model + features\n",
    "    Fully needed\n",
    "1. Determine sampling method + sample\n",
    "    Needed:\n",
    "    - Sample method\n",
    "    - Feasibility/ bounded check\n",
    "2. Evaluate samples\n",
    "    Needed:\n",
    "    - Optimization model\n",
    "3. Determine closeness samples\n",
    "    Needed:\n",
    "    -Distance metric/kernel function\n",
    "4. Fit explanation models:\n",
    "    Needed:\n",
    "    - Train and test split\n",
    "    - Dictionary of candidate functions with hyperparameters\n",
    "    - Performance metric\n",
    "5. Plot feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sample pertubations of instance: normally around original value\n",
    "Args:     orig              - array of original instance parameters\n",
    "          ftr_index_list    - list with indices of originial array to perturb\n",
    "          model_lcl         - black-box model to explain\n",
    "          method            - method to perturb instance. Only option now: normal\n",
    "          var               - variance for pertubation\n",
    "          size              - number of perturbed instances\n",
    "          feasibility_check - check whether perturbed instance is feasible\n",
    "          bounded_check     - check whether perturbed instance is bounded\n",
    "Output:   org_plus_smpl  - array with rows original instance and size perturbed instances\n",
    "'''\n",
    "\n",
    "def sample_perturbations_normal(orig, ftr_index_list, model_lcl, mean = 0, var = 0.2, size = 1000, feasibility_check = True, bounded_check = True):\n",
    "    \n",
    "    org_plus_prtb = [orig]\n",
    "    cntr = 1\n",
    "    incr = 1\n",
    "\n",
    "    while cntr < size:\n",
    "        orig_with_noise = copy.deepcopy(orig)\n",
    "        good_sample = True\n",
    "        \n",
    "        for j in range(len(orig)):\n",
    "            if j in ftr_index_list:\n",
    "                lcl_var = orig_with_noise[j] * var\n",
    "                orig_with_noise[j] = orig_with_noise[j] + np.random.normal(mean, lcl_var)\n",
    "\n",
    "        if feasibility_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, 'feasibility')\n",
    "        if bounded_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, 'bounded')\n",
    "\n",
    "        if good_sample == True:\n",
    "            org_plus_prtb.append(np.asarray(orig_with_noise))\n",
    "            cntr  = cntr + 1\n",
    "        \n",
    "        incr = incr + 1\n",
    "\n",
    "        if incr > size and cntr < size/2:\n",
    "            raise ValueError(\"Too many unbounded or unfeasible samples, change sampling method\")\n",
    "        \n",
    "    org_plus_prtb = np.asarray(org_plus_prtb)\n",
    "\n",
    "    return org_plus_prtb\n",
    "\n",
    "# Perturb instance parameters between -/+ epsilon\n",
    "def sample_perturbations_epsilon(orig, ftr_index_list, model_lcl, epsilon = 1, size = 1000, feasibility_check = True, bounded_check = True):\n",
    "    \n",
    "    org_plus_prtb = [orig]\n",
    "    prtb = np.zeros(len(size),len(ftr_index_list))\n",
    "    cntr = 1\n",
    "    incr = 1\n",
    "\n",
    "    while cntr < size:\n",
    "        orig_with_noise = copy.deepcopy(orig)\n",
    "        \n",
    "        for j in range(len(orig)):\n",
    "            if j in ftr_index_list:\n",
    "                lmb = np.random.uniform(-1, 1)\n",
    "                orig_with_noise[j] = orig_with_noise[j] + lmb * epsilon\n",
    "                prtb[cntr][j] = lmb\n",
    "\n",
    "        if feasibility_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, 'feasibility')\n",
    "        if bounded_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, 'bounded')\n",
    "\n",
    "        if good_sample == True:\n",
    "            org_plus_prtb.append(np.asarray(orig_with_noise))\n",
    "            cntr  = cntr + 1\n",
    "        \n",
    "        incr = incr + 1\n",
    "\n",
    "        if incr > size and cntr < size/2:\n",
    "            raise ValueError(\"Too many unbounded or unfeasible samples, change sampling method\")\n",
    "        \n",
    "    org_plus_prtb = np.asarray(org_plus_prtb)\n",
    "    prtb = np.asarray(prtb)\n",
    "\n",
    "    return org_plus_prtb, prtb\n",
    "\n",
    "\n",
    "# Perturb instance parameters by scaling with factor between lower_bound and upper_bound\n",
    "def sample_perturbations_scalar(orig, ftr_index_list, model_lcl,  lower_bound = 0.2, upper_bound = 2, size = 1000, feasibility_check = True, bounded_check = True):\n",
    "\n",
    "    org_plus_prtb = [orig]\n",
    "    prtb = np.ones(len(size),len(ftr_index_list))\n",
    "    cntr = 1\n",
    "    incr = 1\n",
    "\n",
    "    while cntr < size:\n",
    "        orig_with_noise = copy.deepcopy(orig)\n",
    "        \n",
    "        for j in range(len(orig)):\n",
    "            if j in ftr_index_list:\n",
    "                lmb = np.random.uniform(lower_bound, upper_bound)\n",
    "                orig_with_noise[j] = orig_with_noise[j] * lmb \n",
    "                prtb[cntr][j] = lmb\n",
    "\n",
    "        if feasibility_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, 'feasibility')\n",
    "        if bounded_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, 'bounded')\n",
    "\n",
    "        if good_sample == True:\n",
    "            org_plus_prtb.append(np.asarray(orig_with_noise))\n",
    "            cntr  = cntr + 1\n",
    "        \n",
    "        incr = incr + 1\n",
    "\n",
    "        if incr > size and cntr < size/2:\n",
    "            raise ValueError(\"Too many unbounded or unfeasible samples, change sampling method\")\n",
    "        \n",
    "    org_plus_prtb = np.asarray(org_plus_prtb)\n",
    "    prtb = np.asarray(prtb)\n",
    "    \n",
    "    return org_plus_prtb, prtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Determine weights of samples using distance with respect to original instance (the one to explain)\n",
    "Args:   smpls               - array of perturbed samples of instance, including the original instance as first element\n",
    "        ftr_index_list      - list with indices of originial array used as feature\n",
    "        function            - function to determine weights. If None we defer to RBF-kernel and Euclidean distance\n",
    "        width               - width of RBF kernel. If none, then 0.75 * #features used\n",
    "Output: weights             - array with weights corresponding to samples\n",
    "'''\n",
    "    \n",
    "def std_weight_function(a, b, ftr_index_list, kernel_width = None):\n",
    "    d = np.linalg.norm(a - b)\n",
    "    if kernel_width is None:\n",
    "        krnl_wdth = 0.75 * len(ftr_index_list)\n",
    "    else:\n",
    "        krnl_wdth = kernel_width\n",
    "    return np.exp(-(d ** 2) / (2* krnl_wdth ** 2))\n",
    "    \n",
    "def get_weights_from_samples(smpls, ftr_index_list, function = None, width = None):\n",
    "    \n",
    "    org = smpls[0]\n",
    "    weights = []\n",
    "\n",
    "    for smpl in smpls:\n",
    "        if function is not None:\n",
    "            weights.append(function(org, smpl))\n",
    "        else:\n",
    "            weights.append(std_weight_function(org, smpl, ftr_index_list, width))\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Determine values of samples using black-box model \n",
    "Args:   smpls               - array of perturbed samples of instance\n",
    "        model_lcl           - black-box optimization model\n",
    "Output: values              - array with values to explain corresponding to samples\n",
    "'''\n",
    "\n",
    "def get_values_from_samples(smpls, model_lcl):\n",
    "    values = []\n",
    "    \n",
    "    for smpl in smpls:\n",
    "        values.append(model_lcl(smpl))\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate different kind of white-box models on different set of hyperparameters\n",
    "Args:   model_type          - typpe of white-box model (restricted to specified set)\n",
    "        hyper_prm_dct       - dictionary of hyperparameter values of model\n",
    "        ?_train             - trains sample features/black-box outcome values/weights\n",
    "        ?_test              - test sample features/black-box outcome values/weights\n",
    "        store_all           - binary value. if True, store results of all combinations of hyperparameters. if False, store only hyperparemeters with best fit on train set\n",
    "Output: rtrn_dict           - dictionary containing model fit information\n",
    "'''\n",
    "\n",
    "def model_search(model_type, hyper_prm_dct, X_train, X_test, Y_train, Y_test, W_train, W_test, store_all = False):\n",
    "    \n",
    "    best_perf = np.inf\n",
    "    best_srgt = np.nan\n",
    "    best_prms = np.nan\n",
    "    rtrn_dict = {}\n",
    "\n",
    "    hyper_prm_grid = ParameterGrid(hyper_prm_dct)\n",
    "    for hyper_prm_set in hyper_prm_grid:\n",
    "\n",
    "        if model_type == 'DecisionTreeRegressor':\n",
    "            surrogate = DecisionTreeRegressor(random_state=42, **hyper_prm_set)\n",
    "        elif model_type == 'DecisionTreeClassifier':\n",
    "            surrogate = DecisionTreeClassifier(random_state=42, **hyper_prm_set)\n",
    "        elif model_type == 'LinearRegression':\n",
    "            surrogate = LinearRegression(**hyper_prm_set)\n",
    "        elif model_type == 'RidgeRegression':\n",
    "            surrogate = Ridge(random_state=42, **hyper_prm_set)\n",
    "        elif model_type == 'LASSORegression':\n",
    "            surrogate = Lasso(random_state=42, **hyper_prm_set)\n",
    "        elif model_type == 'SVM':\n",
    "            surrogate = svm(random_state=42, **hyper_prm_set)\n",
    "        elif model_type == 'LogisticRegression':\n",
    "            surrogate = LogisticRegression(random_state=42, **hyper_prm_set)\n",
    "        else:\n",
    "            raise ValueError(\"Model type not yet supported, please choose from: DecisionTreeRegressor, DecisionClassifier, LinearRegression, RidgeRegression, LASSORegression, SVM, LogisticRegression\")\n",
    "\n",
    "        surrogate.fit(X_train, Y_train, sample_weight= W_train)\n",
    "        Y_pred_train = surrogate.predict(X_train)\n",
    "        train_err = mean_squared_error(Y_train, Y_pred_train, sample_weight= W_train)\n",
    "\n",
    "        if store_all == True:\n",
    "            hyper_prm_str = str(hyper_prm_set)\n",
    "            rtrn_dict[hyper_prm_str] = {}\n",
    "            rtrn_dict[hyper_prm_str]['Model'] = surrogate\n",
    "            Y_pred_test = surrogate.predict(X_test)\n",
    "            if model_type in ['DecisionTreeRegressor', 'DecisionTreeClassifier']:\n",
    "                rtrn_dict[hyper_prm_str]['Best model feature importance'] = np.abs(surrogate.feature_importances_)/max(np.sum(np.abs(surrogate.feature_importances_)), 0.00000001)\n",
    "            else:\n",
    "                rtrn_dict[hyper_prm_str]['Best model coefficients'] = surrogate.coef_\n",
    "                rtrn_dict[hyper_prm_str]['Best model feature importance'] = np.abs(surrogate.coef_ * X_train.std(axis=0))/max(np.sum(np.abs(surrogate.coef_ * X_train.std(axis=0))), 0.00000001)\n",
    "                rtrn_dict[hyper_prm_str]['R2'] = r2_score(Y_test, Y_pred_test)\n",
    "            rtrn_dict[hyper_prm_str]['Wmse'] = mean_squared_error(Y_test, Y_pred_test, sample_weight= W_test)\n",
    "            rtrn_dict[hyper_prm_str]['mse']  = mean_squared_error(Y_test, Y_pred_test)\n",
    "            rtrn_dict[hyper_prm_str]['WL1e'] = mean_absolute_error(Y_test, Y_pred_test, sample_weight= W_test)\n",
    "            rtrn_dict[hyper_prm_str]['L1e']  = mean_absolute_error(Y_test, Y_pred_test)\n",
    "            rtrn_dict[hyper_prm_str]['Y_pred_test']  = Y_pred_test\n",
    "            rtrn_dict[hyper_prm_str]['Y_test']  = Y_test\n",
    "\n",
    "        if train_err < best_perf and store_all == False:\n",
    "            best_perf = train_err\n",
    "            best_srgt = surrogate\n",
    "            best_prms = hyper_prm_set\n",
    "    \n",
    "    if store_all == False:\n",
    "        Y_pred_test = best_srgt.predict(X_test)\n",
    "        rtrn_dict['Model'] = best_srgt\n",
    "        rtrn_dict['Best hyperparameters'] = best_prms\n",
    "        if model_type in ['DecisionTreeRegressor', 'DecisionTreeClassifier']:\n",
    "            rtrn_dict['Best model feature importance'] = np.abs(best_srgt.feature_importances_)/max(np.sum(np.abs(best_srgt.feature_importances_)), 0.00000001)\n",
    "        else:\n",
    "            rtrn_dict['Best model coefficients'] = best_srgt.coef_\n",
    "            rtrn_dict['Best model feature importance'] = np.abs(best_srgt.coef_ * X_train.std(axis=0))/max(np.sum(np.abs(best_srgt.coef_ * X_train.std(axis=0))), 0.00000001)\n",
    "            rtrn_dict['R2'] = r2_score(Y_test, Y_pred_test)\n",
    "        rtrn_dict['Wmse'] = mean_squared_error(Y_test, Y_pred_test, sample_weight= W_test)\n",
    "        rtrn_dict['mse']  = mean_squared_error(Y_test, Y_pred_test)\n",
    "        rtrn_dict['WL1e'] = mean_absolute_error(Y_test, Y_pred_test, sample_weight= W_test)\n",
    "        rtrn_dict['L1e']  = mean_absolute_error(Y_test, Y_pred_test)\n",
    "        rtrn_dict['Y_pred_test']  = Y_pred_test\n",
    "        rtrn_dict['Y_test']  = Y_test\n",
    "\n",
    "    return rtrn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split samples in train and test set to evaluate candidate white-box models\n",
    "Args:   pos_mdls            - dictionary with white-box model types as keys and hyperparameter dictionary as values\n",
    "        X, Y, W             - samples, black-box model values, weights\n",
    "        feature_indices     - list of indices corresponding to features used\n",
    "        train_part          - percentage of training data \n",
    "        store_all           - binary value. if True, store results of all combinations of hyperparameters. if False, store only hyperparemeters with best fit on train set\n",
    "Output: outcome_dict        - dictionary containing model fit information per white-box-model type\n",
    "'''\n",
    "\n",
    "def train_test_explanation_models(pos_mdls, X, Y, W, feature_indices, train_part = 0.8, store_all = False):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test, W_train, W_test = train_test_split(X[:,feature_indices], Y, W,\n",
    "                                                                            train_size = train_part, \n",
    "                                                                            test_size = 1-train_part, \n",
    "                                                                            random_state = 100)\n",
    "    \n",
    "    outcome_dict = {}\n",
    "    for model_type in pos_mdls.keys():\n",
    "\n",
    "        hyper_prm_dict = pos_mdls[model_type]\n",
    "        outcome_dict[model_type] = model_search(model_type, hyper_prm_dict, X_train, X_test, Y_train, Y_test, W_train, W_test, store_all)\n",
    "            \n",
    "    return outcome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot feature importance/tree\n",
    "Args:   solution_dict       - dictionary with white-box model types as keys and hyperparameter dictionary as values\n",
    "        features_lbls       - labels of features\n",
    "        surrogate_type      - list of model types to include in plot=\n",
    "Output: outcome_dict        - dictionary containing model fit information per white-box-model type\n",
    "'''\n",
    "\n",
    "def plot_explanation_tree(solution_dict, features_lbls, surrogate_type = None):\n",
    "    if surrogate_type not in ['DecisionTreeRegressor', 'DecisionClassifier']:\n",
    "        raise ValueError(\"surrogate_type should be: 'DecisionTreeRegressor' or 'DecisionClassifier'\")\n",
    "    else:\n",
    "        plt.figure()\n",
    "        plot_tree(solution_dict[surrogate_type]['Model'], filled=True, feature_names = features_lbls)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_explanation_feature_importance(solution_dict, features_lbls, surrogate_types = None):\n",
    "    ind = np.arange(len(features_lbls))\n",
    "    width = 1/len(surrogate_types)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(len(surrogate_types)):\n",
    "        ftr_prm = solution_dict[surrogate_types[i]]['Best model feature importance']\n",
    "        ftr_imp = np.abs(ftr_prm)/np.sum(np.abs(ftr_prm))\n",
    "        ax.barh(ind +i* width, ftr_imp, width, label=surrogate_types[i])\n",
    "\n",
    "    ax.set(yticks=ind + 0.5, yticklabels=features_lbls, ylim=[2*width - 1, len(features_lbls)])\n",
    "    if len(surrogate_types) > 1:\n",
    "        ax.legend()\n",
    "        plt.title('Relative feature importance for different surrogate types.')\n",
    "    else:\n",
    "        plt.title('Relative feature importance for ' + surrogate_types[0] + '  surrogate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set instance and features\n",
    "\n",
    "# Knapsack with logical features\n",
    "KS_vals = [9, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 6]\n",
    "KS_wgts = [0.9, 0.02, 0.03, 0.01, 0.04, 0.005, 0.001, 0.015, 0.09, 0.0001]\n",
    "KS_bdgt = 1\n",
    "# Concatenate variables\n",
    "inst = np.concatenate((KS_vals, KS_wgts, [KS_bdgt]))\n",
    "\n",
    "all_prmt_dict = {}\n",
    "features_lbls = []\n",
    "\n",
    "for i in range(len(KS_vals)):\n",
    "    all_prmt_dict['Value item ' + str(i+1)]  = KS_vals[i]\n",
    "    # features_lbls.append('Value item ' + str(i+1))\n",
    "for i in range(len(KS_wgts)):\n",
    "    all_prmt_dict['Weight item ' + str(i+1)] = KS_wgts[i]\n",
    "    features_lbls.append('Weight item ' + str(i+1))\n",
    "all_prmt_dict['Maximum weight allowed'] = KS_bdgt\n",
    "\n",
    "all_prmt_lbls = list(all_prmt_dict.keys())\n",
    "all_prmt_vals = list(all_prmt_dict.values())\n",
    "\n",
    "features_inds = [all_prmt_lbls.index(key) for key in features_lbls]\n",
    "features_dict = {key: all_prmt_dict[key] for key in features_lbls}\n",
    "features_vals = features_dict.values()\n",
    "\n",
    "# samples_sizes = [100, 500, 1000, 2000]\n",
    "\n",
    "weight_widths = [0.01, 0.1, 0.5, 1, 1.5, 2, 5, 10, 20]\n",
    "\n",
    "pos_mdls_dict = {'DecisionTreeRegressor':  {'max_depth': [3, 4, 5],\n",
    "                                            'min_samples_leaf': [10, 50, 100]},\n",
    "                'LinearRegression':        {},\n",
    "                'RidgeRegression':         {'alpha': [0.1, 0.5, 1, 2, 5, 10, 50]},\n",
    "                'LASSORegression':         {'alpha': [0.1, 0.5, 1, 2, 5, 10, 50]}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary LP knapsack\n",
    "def model_KS_bin(vals, output = 'goal', solver = solver):\n",
    "\n",
    "    # Define a model\n",
    "    model = pyo.ConcreteModel('Knapsack 0-1 model')\n",
    "\n",
    "    # Declare decision variables\n",
    "    model.x = pyo.Var(range(int(((len(vals)-1)/2))), domain=pyo.Binary)\n",
    "\n",
    "    # Declare objective\n",
    "    model.objective = pyo.Objective(expr = sum(vals[i]*model.x[i] for i in range(int(((len(vals)-1)/2)))),\n",
    "                                sense = pyo.maximize)\n",
    "\n",
    "    # Declare constraints\n",
    "    model.budget = pyo.Constraint(expr = sum(vals[i+int(((len(vals)-1)/2))]*model.x[i] for i in range(int(((len(vals)-1)/2)))) <= vals[-1])\n",
    "\n",
    "    # Solve\n",
    "    result = solver.solve(model)\n",
    "\n",
    "    if output == 'goal':\n",
    "        return model.objective()\n",
    "\n",
    "    elif output == 'bounded' or output == 'feasibility':\n",
    "        return result.solver.termination_condition != TerminationCondition.infeasibleOrUnbounded\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Output not supported for model function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples, weights, and values\n",
    "samples = sample_perturbations_normal(all_prmt_vals, features_inds, model_lcl = model_KS_bin)\n",
    "weights = []\n",
    "for wdth in weight_widths:\n",
    "    weights.append(get_weights_from_samples(samples, features_inds, width=wdth))\n",
    "yvalues = get_values_from_samples(samples, model_KS_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_dict = train_test_explanation_models(pos_mdls_dict, samples, yvalues, weights[3], features_inds, store_all=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
