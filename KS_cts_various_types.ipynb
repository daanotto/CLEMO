{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from scipy.optimize import minimize, check_grad, approx_fprime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import pyomo environment and setup gurobi solver\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverStatus, TerminationCondition\n",
    "import gurobipy \n",
    "solver = pyo.SolverFactory(\"gurobi_direct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "nr_items = 25\n",
    "smple_sz = 1000\n",
    "rsmpl_sz = 10\n",
    "epsilon  = 10e-4\n",
    "today = date.today()\n",
    "\n",
    "# Implied variables\n",
    "nr_trgts = nr_items + 1\n",
    "nr_ftres = 2*nr_items\n",
    "nr_ftres_intrcpt = nr_ftres + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "seed_lst = [*range(42, 42+rsmpl_sz)] \n",
    "np.random.seed(seed_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source types: https://github.com/likr/kplib\n",
    "# Type discription source: https://di.ku.dk/forskning/Publikationer/tekniske_rapporter/tekniske-rapporter-2003/03-08.pdf\n",
    "\n",
    "ks_types = ['00Uncorrelated', '01WeaklyCorrelated', '02StronglyCorrelated', '03InverseStronglyCorrelated']\n",
    "tp_insts = ['/s00'+str(i)+'.kp' for i in range(10)]\n",
    "\n",
    "nr_typs  = len(ks_types)\n",
    "nr_inst  = len(tp_insts)\n",
    "f_list   = []\n",
    "\n",
    "ins_b    = []\n",
    "ins_v    = []\n",
    "ins_w    = [] \n",
    "\n",
    "for ks_type in ks_types:\n",
    "    for tp_inst in tp_insts:\n",
    "        file_str = 'Instances/' + ks_type + tp_inst\n",
    "        f = open(file_str, \"r\")\n",
    "        f_list.append(f)\n",
    "        i = 0\n",
    "        lcl_v = []\n",
    "        lcl_w = []\n",
    "        for x in f:\n",
    "            if i == 2:\n",
    "                ins_b.append(int(x))\n",
    "            if i > 3:\n",
    "                x_split = x.split()\n",
    "                lcl_v.append(int(x_split[0]))\n",
    "                lcl_w.append(int(x_split[1]))\n",
    "            i = i+1\n",
    "\n",
    "        ins_v.append(lcl_v)\n",
    "        ins_w.append(lcl_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05717959128434159, 0.05129246176749222, 0.02848829340912167, 0.01752605223981594, 0.03464609554743538, 0.027405602923264313, 0.05305183380701042, 0.020571119231289754, 0.03227771010962241, 0.03951820273379348, 0.061510353227771014, 0.03417241845987278, 0.01908241981323589, 0.05115712545676005, 0.04188658817160644, 0.016984706996887266, 0.061578021383137095, 0.06651779672486129, 0.05487887400189471, 0.0611043442955745, 0.02104479631885235, 0.04939775341724185, 0.06083367167411016, 0.04628501827040195, 0.03200703748815807, 0.006834483691974556, 0.029435647584246855, 0.041345242928677764, 0.06184869400460143, 0.06543510623900392, 0.0323453782649885, 0.05860062254702937, 0.01766138855054811, 0.05454053322506428, 0.03714981729598051, 0.0010150223304912708, 0.048721071863580996, 0.026999593991067803, 0.0558262281770199, 0.04526999593991068, 0.00013533631073216944, 0.03342806875084585, 0.05873595885776154, 0.01651102990932467, 0.02205981864934362, 0.05893896332385979, 0.012992285830288266, 0.03843551224793612, 0.01617268913249425, 0.06550277439437001]\n",
      "[0.05440519691433211, 0.030315333604005956, 0.0054811205846528625, 0.021721477872513197, 0.03437542292597104, 0.06313438895655704, 0.007443497090269319, 0.03735282176207876, 0.047841385843821894, 0.037082149140614425, 0.055149546623359046, 0.03660847205305184, 0.06523210177290567, 0.04087156584111517, 0.03978887535525782, 0.0301123291379077, 0.04039788875355258, 0.026052239815942617, 0.0389768574908648, 0.019691433211530655, 0.012856949519556097, 0.012653945053457842, 0.04148057923940993, 0.044457978075517664, 0.03227771010962241, 0.0060901339829476245, 0.05129246176749222, 0.0593449722560563, 0.06252537555826228, 0.05704425497360942, 0.06083367167411016, 0.06252537555826228, 0.03660847205305184, 0.02652591690350521, 0.04777371768845581, 0.01867641088103938, 0.054946542157260796, 0.05751793206117201, 0.06063066720801191, 0.039924211665989986, 0.06428474759778048, 0.039247530112329135, 0.03051833807010421, 0.044728650696982, 0.06746515089998646, 0.06205169847069969, 0.05372851536067127, 0.0056164568953850314, 0.04148057923940993, 0.03295439166328326]\n"
     ]
    }
   ],
   "source": [
    "print([x/ins_b[0] for x in ins_v[0]])\n",
    "print([x/ins_b[0] for x in ins_w[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the continuous knapsack problem, i.e.,\n",
    "$$\n",
    "\\max c^{\\top}z\\\\\n",
    "s.t. Az\\leq b\\\\\n",
    "z\\geq 0\n",
    "$$\n",
    "Here, $z$ is the decision vector with dimension $n$, nr of items. $c$ is the vector containing all the values of the items, $A$ is the vector containing the weight of the items, and wlog we set $b=1$.\n",
    "To create explanations $c, A$ are used as features here. Hence there are $2n$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous LP knapsack\n",
    "def model_KS_cts(vals, output = 'goal', solver = solver):\n",
    "\n",
    "    # Define a model\n",
    "    model = pyo.ConcreteModel('Knapsack continuous model')\n",
    "\n",
    "    # Declare decision variables\n",
    "    model.x = pyo.Var(range(int(((len(vals)-1)/2))), domain=pyo.NonNegativeReals, bounds=(0, 1))\n",
    "\n",
    "    # Declare objective\n",
    "    model.objective = pyo.Objective(expr = sum(vals[i]*model.x[i] for i in range(int(((len(vals)-1)/2)))),\n",
    "                                sense = pyo.maximize)\n",
    "\n",
    "    # Declare constraints\n",
    "    model.budget = pyo.Constraint(expr = sum(vals[i+int(((len(vals)-1)/2))]*model.x[i] for i in range(int(((len(vals)-1)/2)))) <= vals[-1])\n",
    "\n",
    "    # Solve\n",
    "    result = solver.solve(model)\n",
    "\n",
    "    if output == 'goal':\n",
    "        return model.objective()\n",
    "\n",
    "    elif output == 'bounded' or output == 'feasibility':\n",
    "        return result.solver.termination_condition != TerminationCondition.infeasibleOrUnbounded\n",
    "    \n",
    "    elif output == 'decision vector':\n",
    "        solutions = []\n",
    "        for i in range(int(((len(vals)-1)/2))):\n",
    "            solutions.append(pyo.value(model.x[i]))\n",
    "        return solutions\n",
    "    \n",
    "    elif output == 'all':\n",
    "        solutions = []\n",
    "        solutions.append(model.objective())\n",
    "        for i in range(int(((len(vals)-1)/2))):\n",
    "            solutions.append(pyo.value(model.x[i]))\n",
    "        return solutions\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Output not supported for model function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.751522533495737\n",
      "1.8502720988380643\n",
      "2.201448225923244\n",
      "2.281406295969403\n",
      "1.7669134102255122\n",
      "2.05015936923335\n",
      "1.858186648953836\n",
      "2.281883380106018\n",
      "2.1108784706417842\n",
      "2.030991555671629\n",
      "2.159561766978018\n",
      "2.0234037140676673\n",
      "1.847310243183493\n",
      "1.896170728015741\n",
      "2.0128842860637692\n",
      "2.1408915795266923\n",
      "2.015457342237563\n",
      "1.865024818633066\n",
      "1.754863813229572\n",
      "2.094499815430048\n",
      "2.159561766978018\n",
      "2.0234037140676673\n",
      "1.847310243183493\n",
      "1.896170728015741\n",
      "2.0128842860637692\n",
      "2.1408915795266923\n",
      "2.015457342237563\n",
      "1.865024818633066\n",
      "1.754863813229572\n",
      "2.094499815430048\n",
      "2.1389254517171232\n",
      "2.0228483319315953\n",
      "1.8738626448959241\n",
      "1.915615041427661\n",
      "2.0141131768218212\n",
      "2.12123206528893\n",
      "2.0162004809517784\n",
      "1.894679947494402\n",
      "1.8007973700776387\n",
      "2.080685147622267\n"
     ]
    }
   ],
   "source": [
    "ins_dict = {}\n",
    "for i in range(nr_typs):\n",
    "    ins_dict['Type '+str(i)] = {}\n",
    "    for j in range(nr_inst):\n",
    "        indx = int(10*i + j)\n",
    "        ins_lcl_v = [x/ins_b[indx]*2 for x in ins_v[indx][:nr_items]]\n",
    "        ins_lcl_w = [x/ins_b[indx]*2 for x in ins_w[indx][:nr_items]]\n",
    "        print(sum(ins_lcl_w))\n",
    "        ins_lcl_b = [1.0]\n",
    "        ins_dict['Type '+str(i)]['Instance '+str(j)] = {}\n",
    "        ins_dict['Type '+str(i)]['Instance '+str(j)]['c,A,b'] = np.concatenate((ins_lcl_v, ins_lcl_w, ins_lcl_b))\n",
    "\n",
    "features = [*range(nr_ftres)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample $m=1000$ instances of the knapsack problem. Let $\\bold{X}\\in\\mathbb{R}^{m\\times 2n+1}$ denote the full matrix of samples, then $X_{i}=(X_{i1},..., X_{i(2n)}, 1)$ is the $i$-th sample consisting of samples of all $2n$ features and 1 to ensure a value to multiply the intercept with.\n",
    "\n",
    "Our output vecotr is denoted by $\\bold{Y}\\in\\mathbb{R}^{m\\times n+1}$ We want to explain multiple things $y_i=(c_i^{\\top}z_i^*, z_i^*)$ is the $n+1$ dimensional output vector with $z_i^*$ the optimal decision vector for sample $i$. We set $y_{ij}=c_i^{\\top}z_i^*$ for $j =0$ and $z_{ij}^*$ for $1\\leq j\\leq n$.\n",
    "\n",
    "Moreover, we calculate the weight of eacht istance using the rbf-kernel. Set $W\\in\\mathbb{R}^{m\\times m}$ and let $W_{ii}=W_i$ denote weight of $i$-th sample and set $W_{ij}=0$ when $i\\neq j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help functions\n",
    "\n",
    "# Create samples\n",
    "def sample_perturbations_normal(orig, ftr_index_list, model_lcl, hyperprm = {}, mean = 0, var = 0.2, size = 1000, feasibility_check = True, bounded_check = True):\n",
    "    \n",
    "    org_plus_prtb = [orig]\n",
    "    cntr = 1\n",
    "    incr = 1\n",
    "\n",
    "    while cntr < size:\n",
    "        orig_with_noise = copy.deepcopy(orig)\n",
    "        good_sample = True\n",
    "        \n",
    "        for j in range(len(orig)):\n",
    "            if j in ftr_index_list:\n",
    "                lcl_var = orig_with_noise[j] * var\n",
    "                orig_with_noise[j] = orig_with_noise[j] + np.random.normal(mean, lcl_var)\n",
    "\n",
    "        if feasibility_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, output = 'feasibility', **hyperprm)\n",
    "        if bounded_check:\n",
    "            good_sample = good_sample * model_lcl(orig_with_noise, output = 'bounded', **hyperprm)\n",
    "\n",
    "        if good_sample == True:\n",
    "            org_plus_prtb.append(np.asarray(orig_with_noise))\n",
    "            cntr  = cntr + 1\n",
    "        \n",
    "        incr = incr + 1\n",
    "        \n",
    "    org_plus_prtb = np.asarray(org_plus_prtb)\n",
    "\n",
    "    return org_plus_prtb\n",
    "\n",
    "# Get values from samples\n",
    "def get_values_from_samples(smpls, model_lcl, hyperprm = {}):\n",
    "    values = []\n",
    "    \n",
    "    for smpl in smpls:\n",
    "        values.append(model_lcl(smpl, **hyperprm))\n",
    "    \n",
    "    return values\n",
    "\n",
    "# Determine weight of samples\n",
    "def std_weight_function(a, b, ftr_index_list, kernel_width = None):\n",
    "    d = np.linalg.norm(a - b)\n",
    "    if kernel_width is None:\n",
    "        krnl_wdth = 0.75 * len(ftr_index_list)\n",
    "    else:\n",
    "        krnl_wdth = kernel_width\n",
    "    return np.exp(-(d ** 2) / (2* krnl_wdth ** 2))\n",
    "    \n",
    "def get_weights_from_samples(smpls, ftr_index_list, function = None, width = None):\n",
    "    \n",
    "    org = smpls[0]\n",
    "    weights = []\n",
    "\n",
    "    for smpl in smpls:\n",
    "        if function is not None:\n",
    "            weights.append(function(org, smpl))\n",
    "        else:\n",
    "            weights.append(std_weight_function(org, smpl, ftr_index_list, width))\n",
    "\n",
    "    return weights\n",
    "\n",
    "def get_knn(weights, k):\n",
    "    return sorted(range(len(weights)), key=lambda i: weights[i])[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Instance 0', 'Instance 1', 'Instance 2', 'Instance 3', 'Instance 4', 'Instance 5', 'Instance 6', 'Instance 7', 'Instance 8', 'Instance 9'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_dict['Type 1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0 Instance 0\n",
      "Type 0 Instance 1\n",
      "Type 0 Instance 2\n",
      "Type 0 Instance 3\n",
      "Type 0 Instance 4\n",
      "Type 0 Instance 5\n",
      "Type 0 Instance 6\n",
      "Type 0 Instance 7\n",
      "Type 0 Instance 8\n",
      "Type 0 Instance 9\n",
      "Type 1 Instance 0\n",
      "Type 1 Instance 1\n",
      "Type 1 Instance 2\n",
      "Type 1 Instance 3\n",
      "Type 1 Instance 4\n",
      "Type 1 Instance 5\n",
      "Type 1 Instance 6\n",
      "Type 1 Instance 7\n",
      "Type 1 Instance 8\n",
      "Type 1 Instance 9\n",
      "Type 2 Instance 0\n",
      "Type 2 Instance 1\n",
      "Type 2 Instance 2\n",
      "Type 2 Instance 3\n",
      "Type 2 Instance 4\n",
      "Type 2 Instance 5\n",
      "Type 2 Instance 6\n",
      "Type 2 Instance 7\n",
      "Type 2 Instance 8\n",
      "Type 2 Instance 9\n",
      "Type 3 Instance 0\n",
      "Type 3 Instance 1\n",
      "Type 3 Instance 2\n",
      "Type 3 Instance 3\n",
      "Type 3 Instance 4\n",
      "Type 3 Instance 5\n",
      "Type 3 Instance 6\n",
      "Type 3 Instance 7\n",
      "Type 3 Instance 8\n",
      "Type 3 Instance 9\n"
     ]
    }
   ],
   "source": [
    "for ky1 in ins_dict.keys():\n",
    "    for ky2 in ins_dict[ky1].keys():\n",
    "        print(ky1,ky2)\n",
    "        for i in range(rsmpl_sz):\n",
    "            np.random.seed(seed_lst[i])\n",
    "            b = 'Batch '+ str(i)\n",
    "            ins_dict[ky1][ky2][b] = {}\n",
    "            # Sample new instances\n",
    "            samples = sample_perturbations_normal(ins_dict[ky1][ky2]['c,A,b'], features, model_lcl = model_KS_cts, size=smple_sz)\n",
    "            ins_dict[ky1][ky2][b]['smpl_vls'] = samples[:,features]\n",
    "            ins_dict[ky1][ky2][b]['Samples']  = np.concatenate((ins_dict[ky1][ky2][b]['smpl_vls'],np.ones((smple_sz,1))), axis = 1) \n",
    "\n",
    "            # Find output of samples\n",
    "            ins_dict[ky1][ky2][b]['Actuals']  = get_values_from_samples(samples, model_KS_cts, hyperprm = {'output':'all'})\n",
    "\n",
    "            # Find weights of samples\n",
    "            d_list = []\n",
    "            for x in samples:\n",
    "                d_list.append(np.linalg.norm(samples[0] - x))\n",
    "\n",
    "            ins_dict[ky1][ky2][b]['Weights'] = get_weights_from_samples(samples, features, width=np.mean(d_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we introduce a $\\bm{\\beta}\\in\\mathbb{R}^{n+1\\times 2n+1}$ consisting of the model variables. Here $\\beta_{jk}$ is the lin. regression variable corresponding to output $j$ and feature $k$. Note, that $\\beta_{j(2n+1)}$ corresponds to the intercept variable of output $j$. This way $\\bm{X\\beta}\\approx \\bm{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_vls_intr = ins_dict['Type 0']['Instance 0']['Batch 1']['Samples']\n",
    "y_vals = ins_dict['Type 0']['Instance 0']['Batch 1']['Actuals']\n",
    "wght_vls = ins_dict['Type 0']['Instance 0']['Batch 1']['Weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following loss function (lss_all):\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\bm{\\beta}) = &\\sum_{i=1}^m W_i  \\sum_{j=0}^n\\left(Y_{ij}-\\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}\\right)^2\\\\\n",
    "&+\\lambda_{obj}\\sum_{i=1}^m W_i  \\left(\\sum_{k=1}^{2n+1}X_{ik}\\beta_{0k}-\\sum_{j=1}^n c_{ij} \\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}\\right)^2\\\\\n",
    "&+\\lambda_{cns}\\sum_{i=1}^m W_i  \\max\\left\\{0,\\sum_{j=1}^n A_{ij} \\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}-1\\right\\}\n",
    "\\end{align}\n",
    "Note that in here for the knapsack problem, $c_{ij}=X_{ij}$ is the value of item $j$ in sample $i$, and $A_{ij}=X_{i(j+n)}$ is the weight of item $j$ in sample $i$.\n",
    "\n",
    "We can provide the Jacobian of $\\mathcal{L}$ as follows. (1) and (2) are differentiable. For (3), we can provide a subgradient yielding the following partial derivatives:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial \\beta_{0k}} = &\\sum_{i=1}^m (-2X_{ik})W_i  \\left(Y_{i0}-\\sum_{k=1}^{2n+1}X_{ik}\\beta_{0k}\\right)\\\\\n",
    "&+\\lambda_{obj}\\sum_{i=1}^m (2X_{ik})W_i  \\left(\\sum_{k=1}^{2n+1}X_{ik}\\beta_{0k}-\\sum_{j=1}^n c_{ij} \\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}\\right)\\\\\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial \\beta_{jk}} = &\\sum_{i=1}^m (-2X_{ik})W_i  \\left(Y_{ij}-\\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}\\right)& j>0\\\\\n",
    "&+\\lambda_{obj}\\sum_{i=1}^m (-2c_{ij}X_{ik})W_i  \\left(\\sum_{k=1}^{2n+1}X_{i0}\\beta_{0k}-\\sum_{j=1}^n c_{ij} \\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}\\right)\\\\\n",
    "&+\\lambda_{cns}\\sum_{i=1}^m (A_{ij}X_{ik})W_i  \\cdot\\left[\\sum_{j=1}^n A_{ij} \\sum_{k=1}^{2n+1}X_{ik}\\beta_{jk}>1\\right]_{boolean} \n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function is the sum of the standard prediction loss,\n",
    "# the objective loss, and the contraint loss\n",
    "\n",
    "def lss_all(beta, X = smpl_vls_intr, Y = y_vals, W = wght_vls, lgr_obj = 1, lgr_cns = 1, oneD=True, region='all'):\n",
    "    if oneD == True:\n",
    "        beta = beta.reshape(nr_ftres_intrcpt, nr_trgts)\n",
    "\n",
    "    if region == 'all':\n",
    "        indc = [*range(len(X))] \n",
    "    elif isinstance(region, float) or isinstance(region, int):\n",
    "        indc = get_knn(weights=W, k =int(region *len(W) / 100))\n",
    "    elif region == 'present problem':\n",
    "        indc = [0]\n",
    "        \n",
    "    std_err = np.sum(np.matmul(np.diag(W), np.square(Y - np.matmul(X, beta))))\n",
    "    obj_err = np.sum(np.matmul(np.diag(np.array(W)), np.square(np.matmul(X, beta)[:,0] - np.sum(np.multiply(np.matmul(X, beta)[:,1:], X[:,:nr_items]), axis=1)))[indc])\n",
    "    cns_err = np.sum(np.matmul(np.diag(np.array(W)), np.maximum(np.zeros(len(W)),  np.sum(np.multiply(np.matmul(X, beta)[:,1:], X[:,nr_items:-1]),axis=1)-np.ones(len(W))))[indc])\n",
    "\n",
    "    tot_err = std_err + lgr_obj * obj_err + lgr_cns * cns_err \n",
    "    return tot_err\n",
    "\n",
    "# Functions for the three components of the loss function seperately\n",
    "def lss_std(beta, X = smpl_vls_intr, Y = y_vals, W = wght_vls, oneD=True):\n",
    "    if oneD == True:\n",
    "        beta = beta.reshape(nr_ftres_intrcpt, nr_trgts)\n",
    "    return np.sum(np.matmul(np.diag(W),np.square(Y - np.matmul(X, beta))))\n",
    "\n",
    "def lss_obj(beta, X = smpl_vls_intr, W = wght_vls, oneD=True, Y = y_vals):\n",
    "    if oneD == True:\n",
    "        beta = beta.reshape(nr_ftres_intrcpt, nr_trgts)\n",
    "    return np.sum(np.matmul(np.diag(W),np.square(np.matmul(X, beta)[:,0]-np.sum(np.multiply(np.matmul(X, beta)[:,1:],X[:,:nr_items]), axis=1))))\n",
    "\n",
    "def lss_cns(beta, X = smpl_vls_intr, W = wght_vls, oneD=True, Y = y_vals):\n",
    "    if oneD == True:\n",
    "        beta = beta.reshape(nr_ftres_intrcpt, nr_trgts)\n",
    "    return np.sum(np.matmul(np.diag(W),np.maximum(np.zeros(len(W)),  np.sum(np.multiply(np.matmul(X, beta)[:,1:],X[:,nr_items:-1]),axis=1)-np.ones(len(W)))))\n",
    "\n",
    "# Jacobian using subgradient\n",
    "def lss_all_jac_sg(beta, X = smpl_vls_intr, Y = y_vals, W = wght_vls, lgr_obj = 1, lgr_cns = 1, oneD=True, region='all'):\n",
    "    grad = np.zeros((nr_ftres_intrcpt, nr_trgts))\n",
    "    if oneD == True:\n",
    "        beta = beta.reshape(nr_ftres_intrcpt, nr_trgts)\n",
    "\n",
    "    if region == 'all':\n",
    "        indc = [*range(len(X))] \n",
    "    elif isinstance(region, float) or isinstance(region, int):\n",
    "        indc = get_knn(W, int(region *len(W) / 100))\n",
    "    elif region == 'present problem':\n",
    "        indc = [0]\n",
    "\n",
    "    tmp_std = (Y - np.matmul(X, beta))\n",
    "    tmp_obj = (np.matmul(X, beta)[:,0]-np.sum(np.multiply(np.matmul(X, beta)[:,1:],X[:,:nr_items]), axis=1))\n",
    "    tmp_cns = ((np.sum(np.multiply(np.matmul(X, beta)[:,1:],X[:,nr_items:-1]),axis=1)>np.ones(len(W))).astype(int))  \n",
    "\n",
    "\n",
    "    for k in range(len(grad)):\n",
    "        for j in range(len(grad[0])):\n",
    "            grad[k][j] = grad[k][j] - 2 * (sum(W[i] * X[i][k] * tmp_std[i][j] for i in range(len(X))))\n",
    "            if j == 0:\n",
    "                grad[k][j] = grad[k][j] + 2 * lgr_obj * (sum(W[i] * X[i][k] * tmp_obj[i] for i in indc))\n",
    "                pass\n",
    "            else:\n",
    "                grad[k][j] = grad[k][j] - 2 * lgr_obj * (sum(W[i] * X[i][k] * X[i][j-1] * tmp_obj[i] for i in indc))\n",
    "                grad[k][j] = grad[k][j] + lgr_cns * (sum(W[i] * tmp_cns[i] * X[i][k] * X[i][j+nr_items-1] for i in indc))\n",
    "                pass\n",
    "    grad_flat = grad.flatten()\n",
    "    return grad_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for the three components of the loss function seperately with predictions\n",
    "def lss_std_pred(X = smpl_vls_intr, Y = y_vals, W = wght_vls, P=np.zeros(np.shape(y_vals))):\n",
    "    return np.sum(np.matmul(np.diag(W),np.square(Y - P)))\n",
    "\n",
    "def lss_obj_pred(X = smpl_vls_intr, Y = y_vals, W = wght_vls, P=np.zeros(np.shape(y_vals))):\n",
    "    return np.sum(np.matmul(np.diag(W),np.square(P[:,0]-np.sum(np.multiply(P[:,1:],X[:,:nr_items]), axis=1))))\n",
    "\n",
    "def lss_cns_pred(X = smpl_vls_intr, Y = y_vals, W = wght_vls, P=np.zeros(np.shape(y_vals))):\n",
    "    return np.sum(np.matmul(np.diag(W),np.maximum(np.zeros(len(W)),  np.sum(np.multiply(P[:,1:],X[:,nr_items:-1]),axis=1)-np.ones(len(W)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0 Instance 0\n",
      "641.4265576153322\n",
      "0.32415945478072994\n",
      "4.95485576001823 \n",
      "\n",
      "Type 0 Instance 1\n",
      "254.12046332898916\n",
      "0.045708033187807556\n",
      "3.0862424776525255 \n",
      "\n",
      "Type 0 Instance 2\n",
      "634.7044296081741\n",
      "0.3169982632199272\n",
      "6.533657840533486 \n",
      "\n",
      "Type 0 Instance 3\n",
      "541.3744462380722\n",
      "0.38181593002767356\n",
      "7.427280649266891 \n",
      "\n",
      "Type 0 Instance 4\n",
      "210.962214548214\n",
      "0.01658293600957903\n",
      "3.0701256115794573 \n",
      "\n",
      "Type 0 Instance 5\n",
      "360.732229064059\n",
      "0.5091397087499276\n",
      "6.72327705216243 \n",
      "\n",
      "Type 0 Instance 6\n",
      "390.43572510087154\n",
      "0.3071660534581578\n",
      "6.112572265161637 \n",
      "\n",
      "Type 0 Instance 7\n",
      "344.6759667684256\n",
      "0.10570406108839728\n",
      "4.441308871210364 \n",
      "\n",
      "Type 0 Instance 8\n",
      "520.827241892191\n",
      "0.15158445081560576\n",
      "5.264841334386356 \n",
      "\n",
      "Type 0 Instance 9\n",
      "461.67552528604364\n",
      "0.2411428036952301\n",
      "7.122244383725182 \n",
      "\n",
      "Type 1 Instance 0\n",
      "1255.504909760713\n",
      "1.0461268421250596\n",
      "10.120479292782424 \n",
      "\n",
      "Type 1 Instance 1\n",
      "1012.3040069767322\n",
      "1.0932306059770471\n",
      "10.317964277001586 \n",
      "\n",
      "Type 1 Instance 2\n",
      "1109.61297937817\n",
      "0.8846118334584769\n",
      "8.790927197237451 \n",
      "\n",
      "Type 1 Instance 3\n",
      "1051.6405529892118\n",
      "0.9690704232248811\n",
      "8.760911302710909 \n",
      "\n",
      "Type 1 Instance 4\n",
      "1198.7916369891484\n",
      "0.9301902724827547\n",
      "10.212527619051222 \n",
      "\n",
      "Type 1 Instance 5\n",
      "1051.0601288419502\n",
      "1.1592576225062754\n",
      "10.623793204037554 \n",
      "\n",
      "Type 1 Instance 6\n",
      "1168.2908424370064\n",
      "0.8932559782047118\n",
      "9.083896036029246 \n",
      "\n",
      "Type 1 Instance 7\n",
      "919.6474885984645\n",
      "1.0982849720947192\n",
      "9.324372026863553 \n",
      "\n",
      "Type 1 Instance 8\n",
      "977.2715049685864\n",
      "0.7755815520500018\n",
      "8.490268193963324 \n",
      "\n",
      "Type 1 Instance 9\n",
      "1025.9357460504125\n",
      "1.0301591559303978\n",
      "9.97240969603201 \n",
      "\n",
      "Type 2 Instance 0\n",
      "1260.2288011884527\n",
      "1.3855646312642764\n",
      "10.290529825493635 \n",
      "\n",
      "Type 2 Instance 1\n",
      "988.9546643039951\n",
      "1.4853719826513263\n",
      "10.632658740271772 \n",
      "\n",
      "Type 2 Instance 2\n",
      "1049.400166298257\n",
      "1.1404581045106728\n",
      "9.255784338630953 \n",
      "\n",
      "Type 2 Instance 3\n",
      "1075.533711421626\n",
      "1.2178013843392574\n",
      "9.29576413268203 \n",
      "\n",
      "Type 2 Instance 4\n",
      "1097.53625712093\n",
      "1.3633356221391444\n",
      "10.460276293411154 \n",
      "\n",
      "Type 2 Instance 5\n",
      "1093.274278690388\n",
      "1.551756587238672\n",
      "11.054489805727247 \n",
      "\n",
      "Type 2 Instance 6\n",
      "1157.4269724108208\n",
      "1.3369252520127781\n",
      "9.482692669782729 \n",
      "\n",
      "Type 2 Instance 7\n",
      "889.2955689705173\n",
      "1.4504333447250606\n",
      "9.60642805664995 \n",
      "\n",
      "Type 2 Instance 8\n",
      "966.3582742406693\n",
      "1.1231697855226224\n",
      "9.367818836576522 \n",
      "\n",
      "Type 2 Instance 9\n",
      "1013.7455698085602\n",
      "1.4873056700189484\n",
      "10.705501740519395 \n",
      "\n",
      "Type 3 Instance 0\n",
      "1268.513521505964\n",
      "0.760521429201854\n",
      "9.874551733669819 \n",
      "\n",
      "Type 3 Instance 1\n",
      "1014.5188722724574\n",
      "0.763494649155545\n",
      "9.59982218755571 \n",
      "\n",
      "Type 3 Instance 2\n",
      "1076.367803273567\n",
      "0.5774638662468793\n",
      "8.327898066793217 \n",
      "\n",
      "Type 3 Instance 3\n",
      "1127.6450586739554\n",
      "0.6193355402260307\n",
      "8.61585703432467 \n",
      "\n",
      "Type 3 Instance 4\n",
      "1163.7322438401966\n",
      "0.6948505895335767\n",
      "9.222828299172939 \n",
      "\n",
      "Type 3 Instance 5\n",
      "1124.033768189171\n",
      "0.8482490872231917\n",
      "10.177493786493844 \n",
      "\n",
      "Type 3 Instance 6\n",
      "1175.684800507964\n",
      "0.7037738122690016\n",
      "8.977347725137287 \n",
      "\n",
      "Type 3 Instance 7\n",
      "991.831162059039\n",
      "0.6070776270293734\n",
      "8.344332755904986 \n",
      "\n",
      "Type 3 Instance 8\n",
      "1096.7146106482433\n",
      "0.48091707649415466\n",
      "7.626227029044688 \n",
      "\n",
      "Type 3 Instance 9\n",
      "1054.5879985274407\n",
      "0.7480048843610362\n",
      "9.55753520140219 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each output j we fit a seperate linear regression model. \n",
    "# The variables of these models function as an initial beta, \n",
    "# a warm start to minimize the loss function later on.\n",
    "def get_warm_start_linreg(x, y, w):\n",
    "    models = []\n",
    "    for i in range(len(y[0])):\n",
    "        clf = LinearRegression()\n",
    "        y_loc = [x[i] for x in y] \n",
    "        clf.fit(x, y_loc, sample_weight = w)\n",
    "        models.append(clf)\n",
    "\n",
    "    wrm_strt_t = np.ones((len(y[0]), len(features)+1))\n",
    "    for i in range(len(models)):\n",
    "        for j in range(len(features)):\n",
    "            wrm_strt_t[i][j] = models[i].coef_[j]\n",
    "        wrm_strt_t[i][j+1] = models[i].intercept_\n",
    "    wrm_strt = np.transpose(wrm_strt_t)\n",
    "    return wrm_strt\n",
    "\n",
    "for ky1 in ins_dict.keys():\n",
    "    for ky2 in ins_dict[ky1].keys():\n",
    "        b = 'Batch 0'\n",
    "        wrm_strt_lcl  = get_warm_start_linreg(x = ins_dict[ky1][ky2][b]['smpl_vls'], y = ins_dict[ky1][ky2][b]['Actuals'], w = ins_dict[ky1][ky2][b]['Weights'])\n",
    "        print(ky1,ky2)\n",
    "        # print(ins_dict[key]['wrm_strt '+str(1)])\n",
    "        print(lss_std(wrm_strt_lcl, X = ins_dict[ky1][ky2][b]['Samples'], Y = ins_dict[ky1][ky2][b]['Actuals'], W =ins_dict[ky1][ky2][b]['Weights']))\n",
    "        print(lss_obj(wrm_strt_lcl, X = ins_dict[ky1][ky2][b]['Samples'], Y = ins_dict[ky1][ky2][b]['Actuals'], W =ins_dict[ky1][ky2][b]['Weights']))\n",
    "        print(lss_cns(wrm_strt_lcl, X = ins_dict[ky1][ky2][b]['Samples'], Y = ins_dict[ky1][ky2][b]['Actuals'], W =ins_dict[ky1][ky2][b]['Weights']), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lss_all_lmb(input, lmb_1, lmb_2):\n",
    "    return lss_all(beta = input, lgr_obj=lmb_1, lgr_cns=lmb_2)\n",
    "\n",
    "def lss_all_jac_lmb(input, lmb_1, lmb_2):\n",
    "    return lss_all_jac_sg(beta = input, lgr_obj=lmb_1, lgr_cns=lmb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lss_all_input(input, X, Y, W, lmb_1, lmb_2, region):\n",
    "    return lss_all(beta = input, X=X, Y=Y, W=W, lgr_obj=lmb_1, lgr_cns=lmb_2, region=region)\n",
    "\n",
    "def lss_all_jac_input(input, X, Y, W, lmb_1, lmb_2, region):\n",
    "    return lss_all_jac_sg(beta = input, X=X, Y=Y, W=W, lgr_obj=lmb_1, lgr_cns=lmb_2, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: Optimization terminated successfully\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 671.4011729934911\n",
      "       x: [ 7.474e-01  9.230e+00 ...  1.882e+00  1.662e+00]\n",
      "     nit: 260\n",
      "     jac: [ 1.035e-03  6.011e-01 ...  4.113e+00  2.911e+00]\n",
      "    nfev: 730\n",
      "    njev: 260\n"
     ]
    }
   ],
   "source": [
    "b = 'Batch '+ str(0)\n",
    "X_lcl = ins_dict['Type 0']['Instance 0'][b]['Samples']\n",
    "Y_lcl = ins_dict['Type 0']['Instance 0'][b]['Actuals']\n",
    "W_lcl = ins_dict['Type 0']['Instance 0'][b]['Weights']\n",
    "wrm_start_lcl = get_warm_start_linreg(x = X_lcl[:,features], y = Y_lcl, w = W_lcl).flatten()\n",
    "args_RLR = (X_lcl, Y_lcl, W_lcl, 100, 10, 'all')\n",
    "#Check grad provided\n",
    "sol_RLR_lcl = minimize(lss_all_input, wrm_start_lcl, args = args_RLR, method='SLSQP', jac=lss_all_jac_input, options = {'maxiter': 1000})\n",
    "print(sol_RLR_lcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol_RLR_lcl_wo = minimize(lss_all_input, wrm_start_lcl, args = args_RLR, method='SLSQP', options = {'maxiter': 1000})\n",
    "# print(sol_RLR_lcl_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_methods_standard = {'Standard Linear Regression': {}, \n",
    "                        'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': max(int(0.05*smple_sz), 50)}, \n",
    "                        'Regularized Linear Regression': {'Region': ['all']}}\n",
    "dict_methods = {}\n",
    "b = 'Batch 0'\n",
    "for ky1 in ins_dict.keys():\n",
    "    dict_methods[ky1] = {}\n",
    "    for ky2 in ins_dict[ky1].keys():\n",
    "        wrm_strt_lcl  = get_warm_start_linreg(x = ins_dict[ky1][ky2][b]['smpl_vls'], y = ins_dict[ky1][ky2][b]['Actuals'], w = ins_dict[ky1][ky2][b]['Weights'])\n",
    "        lcl_lss_std = lss_std(wrm_strt_lcl, X = ins_dict[ky1][ky2][b]['Samples'], Y = ins_dict[ky1][ky2][b]['Actuals'], W =ins_dict[ky1][ky2][b]['Weights'])\n",
    "        lcl_lss_obj = max(lss_obj(wrm_strt_lcl, X = ins_dict[ky1][ky2][b]['Samples'], Y = ins_dict[ky1][ky2][b]['Actuals'], W =ins_dict[ky1][ky2][b]['Weights']),10e-4)\n",
    "        lcl_lss_cns = max(lss_cns(wrm_strt_lcl, X = ins_dict[ky1][ky2][b]['Samples'], Y = ins_dict[ky1][ky2][b]['Actuals'], W =ins_dict[ky1][ky2][b]['Weights']),10e-4)\n",
    "\n",
    "        dict_methods[ky1][ky2] = copy.deepcopy(dict_methods_standard)\n",
    "        # print(lcl_lss_std)\n",
    "        # print(lcl_lss_obj)\n",
    "        # print(lcl_lss_cns)\n",
    "        # print((np.round(0.5*lcl_lss_std/lcl_lss_obj,decimals=1), 10), (np.round(0.5*lcl_lss_std/lcl_lss_obj, decimals=1),1))\n",
    "        dict_methods[ky1][ky2]['Regularized Linear Regression']['Lambdas'] = [(np.round(0.5*lcl_lss_std/lcl_lss_obj,decimals=1), np.round(0.5*lcl_lss_std/lcl_lss_cns,decimals=1))]\n",
    "                                                                            #   , (np.round(0.5*lcl_lss_std/lcl_lss_obj,decimals=1), 10), (np.round(0.5*lcl_lss_std/lcl_lss_obj, decimals=1),1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Type 0': {'Instance 0': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(989.4), np.float64(64.7))]}}, 'Instance 1': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(2779.8), np.float64(41.2))]}}, 'Instance 2': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(1001.1), np.float64(48.6))]}}, 'Instance 3': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(708.9), np.float64(36.4))]}}, 'Instance 4': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(6360.8), np.float64(34.4))]}}, 'Instance 5': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(354.3), np.float64(26.8))]}}, 'Instance 6': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(635.5), np.float64(31.9))]}}, 'Instance 7': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(1630.4), np.float64(38.8))]}}, 'Instance 8': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(1717.9), np.float64(49.5))]}}, 'Instance 9': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(957.3), np.float64(32.4))]}}}, 'Type 1': {'Instance 0': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(600.1), np.float64(62.0))]}}, 'Instance 1': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(463.0), np.float64(49.1))]}}, 'Instance 2': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(627.2), np.float64(63.1))]}}, 'Instance 3': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(542.6), np.float64(60.0))]}}, 'Instance 4': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(644.4), np.float64(58.7))]}}, 'Instance 5': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(453.3), np.float64(49.5))]}}, 'Instance 6': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(654.0), np.float64(64.3))]}}, 'Instance 7': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(418.7), np.float64(49.3))]}}, 'Instance 8': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(630.0), np.float64(57.6))]}}, 'Instance 9': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(498.0), np.float64(51.4))]}}}, 'Type 2': {'Instance 0': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(454.8), np.float64(61.2))]}}, 'Instance 1': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(332.9), np.float64(46.5))]}}, 'Instance 2': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(460.1), np.float64(56.7))]}}, 'Instance 3': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(441.6), np.float64(57.9))]}}, 'Instance 4': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(402.5), np.float64(52.5))]}}, 'Instance 5': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(352.3), np.float64(49.4))]}}, 'Instance 6': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(432.9), np.float64(61.0))]}}, 'Instance 7': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(306.6), np.float64(46.3))]}}, 'Instance 8': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(430.2), np.float64(51.6))]}}, 'Instance 9': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(340.8), np.float64(47.3))]}}}, 'Type 3': {'Instance 0': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(834.0), np.float64(64.2))]}}, 'Instance 1': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(664.4), np.float64(52.8))]}}, 'Instance 2': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(932.0), np.float64(64.6))]}}, 'Instance 3': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(910.4), np.float64(65.4))]}}, 'Instance 4': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(837.4), np.float64(63.1))]}}, 'Instance 5': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(662.6), np.float64(55.2))]}}, 'Instance 6': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(835.3), np.float64(65.5))]}}, 'Instance 7': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(816.9), np.float64(59.4))]}}, 'Instance 8': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(1140.2), np.float64(71.9))]}}, 'Instance 9': {'Standard Linear Regression': {}, 'Decision Tree Regression': {'max_depth': 5, 'min_samples_leaf': 50}, 'Regularized Linear Regression': {'Region': ['all'], 'Lambdas': [(np.float64(704.9), np.float64(55.2))]}}}}\n"
     ]
    }
   ],
   "source": [
    "print(dict_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0 Instance 0\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 1\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 2\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 3\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 4\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 5\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 6\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 7\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 8\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 0 Instance 9\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 0\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 1\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 2\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 3\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 4\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 5\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 6\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 7\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 8\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 1 Instance 9\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 0\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 1\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 2\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 3\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 4\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 5\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 6\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 7\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 8\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 2 Instance 9\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 0\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 1\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 2\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 3\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 4\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 5\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 6\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 7\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 8\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Type 3 Instance 9\n",
      "Batch 0\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 1\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 2\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 3\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 4\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 5\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 6\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 7\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 8\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n",
      "Batch 9\n",
      "Standard Linear Regression\n",
      "Decision Tree Regression\n",
      "Regularized Linear Regression\n"
     ]
    }
   ],
   "source": [
    "for ky1 in ins_dict.keys():\n",
    "    for ky2 in ins_dict[ky1].keys():\n",
    "        print(ky1,ky2)\n",
    "        for i in range(rsmpl_sz):\n",
    "            b = 'Batch '+ str(i)\n",
    "            print(b)\n",
    "            X_lcl = np.array(ins_dict[ky1][ky2][b]['Samples'])\n",
    "            Y_lcl = np.array(ins_dict[ky1][ky2][b]['Actuals'])\n",
    "            W_lcl = np.array(ins_dict[ky1][ky2][b]['Weights'])\n",
    "            wrm_start_lcl = get_warm_start_linreg(x = X_lcl[:,features], y = Y_lcl, w = W_lcl).flatten()\n",
    "\n",
    "            for method in dict_methods[ky1][ky2].keys():\n",
    "                ins_dict[ky1][ky2][b][method] = {}\n",
    "                if method == 'Standard Linear Regression':\n",
    "                    print('Standard Linear Regression')\n",
    "                    ins_dict[ky1][ky2][b][method]['Beta'] = np.transpose(wrm_start_lcl.reshape(nr_ftres_intrcpt, nr_trgts))\n",
    "\n",
    "                    for j in range(nr_trgts):\n",
    "                        ins_dict[ky1][ky2][b][method]['Contribution Target ' + str(j)] = np.multiply(ins_dict[ky1][ky2][b][method]['Beta'][j,:-1], ins_dict[ky1][ky2]['c,A,b'][features])\n",
    "\n",
    "                    ins_dict[ky1][ky2][b][method]['Error Prediction'] = lss_std(wrm_start_lcl, X = X_lcl, Y = Y_lcl, W = W_lcl)\n",
    "                    ins_dict[ky1][ky2][b][method]['Error Objective']  = lss_obj(wrm_start_lcl, X = X_lcl, Y = Y_lcl, W = W_lcl)\n",
    "                    ins_dict[ky1][ky2][b][method]['Error Constraint'] = lss_cns(wrm_start_lcl, X = X_lcl, Y = Y_lcl, W = W_lcl)\n",
    "\n",
    "                elif method == 'Regularized Linear Regression':\n",
    "                    print('Regularized Linear Regression')\n",
    "                    for rgn in dict_methods[ky1][ky2][method]['Region']:\n",
    "                        for lmbds in dict_methods[ky1][ky2][method]['Lambdas']:\n",
    "                            ins_dict[ky1][ky2][b][method] = {}\n",
    "\n",
    "                            args_RLR = (X_lcl, Y_lcl, W_lcl, lmbds[0], lmbds[1], rgn)\n",
    "                            sol_RLR_lcl = minimize(lss_all_input, wrm_start_lcl, args = args_RLR, method='SLSQP', jac = lss_all_jac_input, options = {'maxiter': 1000}).x\n",
    "                            ins_dict[ky1][ky2][b][method]['Beta'] = np.transpose(sol_RLR_lcl.reshape(nr_ftres_intrcpt, nr_trgts))\n",
    "                            for j in range(nr_trgts):\n",
    "                                ins_dict[ky1][ky2][b][method]['Contribution Target ' + str(j)] = np.multiply(ins_dict[ky1][ky2][b][method]['Beta'][j,:-1], ins_dict[ky1][ky2]['c,A,b'][features])  \n",
    "                            \n",
    "                            ins_dict[ky1][ky2][b][method]['Error Prediction'] = lss_std(sol_RLR_lcl, X = X_lcl, Y = Y_lcl, W = W_lcl)\n",
    "                            ins_dict[ky1][ky2][b][method]['Error Objective']  = lss_obj(sol_RLR_lcl, X = X_lcl, Y = Y_lcl, W = W_lcl)\n",
    "                            ins_dict[ky1][ky2][b][method]['Error Constraint'] = lss_cns(sol_RLR_lcl, X = X_lcl, Y = Y_lcl, W = W_lcl)\n",
    "\n",
    "                elif method == 'Decision Tree Regression':\n",
    "                    print('Decision Tree Regression')\n",
    "                    hpr_prm = dict_methods[ky1][ky2][method]\n",
    "                    ins_dict[ky1][ky2][b][method]['Beta'] = np.transpose(wrm_start_lcl.reshape(nr_ftres_intrcpt, nr_trgts))\n",
    "                    Y_pred = []\n",
    "                    for j in range(nr_trgts):\n",
    "                        dtr = DecisionTreeRegressor(**hpr_prm)\n",
    "                        dtr.fit(X_lcl[:,:-1], Y_lcl[:,j], sample_weight = W_lcl)\n",
    "                        Y_pred.append(dtr.predict(X_lcl[:,:-1]))\n",
    "                        ins_dict[ky1][ky2][b][method]['Contribution Target ' + str(j)] = dtr.feature_importances_\n",
    "                    Y_pred = np.transpose(np.array(Y_pred))\n",
    "                    ins_dict[ky1][ky2][b][method]['Error Prediction'] = lss_std_pred(X = X_lcl, Y = Y_lcl, W = W_lcl, P = Y_pred)\n",
    "                    ins_dict[ky1][ky2][b][method]['Error Objective']  = lss_obj_pred(X = X_lcl, Y = Y_lcl, W = W_lcl, P = Y_pred)\n",
    "                    ins_dict[ky1][ky2][b][method]['Error Constraint'] = lss_cns_pred(X = X_lcl, Y = Y_lcl, W = W_lcl, P = Y_pred)\n",
    "                    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\dotto1\\appdata\\local\\miniconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\dotto1\\appdata\\local\\miniconda3\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Contribution Target 0', 'Contribution Target 1', 'Contribution Target 2', 'Contribution Target 3', 'Contribution Target 4', 'Contribution Target 5', 'Contribution Target 6', 'Contribution Target 7', 'Contribution Target 8', 'Contribution Target 9', 'Contribution Target 10', 'Contribution Target 11', 'Contribution Target 12', 'Contribution Target 13', 'Contribution Target 14', 'Contribution Target 15', 'Contribution Target 16', 'Contribution Target 17', 'Contribution Target 18', 'Contribution Target 19', 'Contribution Target 20', 'Contribution Target 21', 'Contribution Target 22', 'Contribution Target 23', 'Contribution Target 24', 'Contribution Target 25']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type nr</th>\n",
       "      <th>Instance nr</th>\n",
       "      <th>Batch nr</th>\n",
       "      <th>Method</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Error Prediction</th>\n",
       "      <th>Error Objective</th>\n",
       "      <th>Error Constraint</th>\n",
       "      <th>Contribution Target 0 Val\\n1</th>\n",
       "      <th>Contribution Target 0 Val\\n2</th>\n",
       "      <th>...</th>\n",
       "      <th>Contribution Target 25 Wgt\\n16</th>\n",
       "      <th>Contribution Target 25 Wgt\\n17</th>\n",
       "      <th>Contribution Target 25 Wgt\\n18</th>\n",
       "      <th>Contribution Target 25 Wgt\\n19</th>\n",
       "      <th>Contribution Target 25 Wgt\\n20</th>\n",
       "      <th>Contribution Target 25 Wgt\\n21</th>\n",
       "      <th>Contribution Target 25 Wgt\\n22</th>\n",
       "      <th>Contribution Target 25 Wgt\\n23</th>\n",
       "      <th>Contribution Target 25 Wgt\\n24</th>\n",
       "      <th>Contribution Target 25 Wgt\\n25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Type 0</td>\n",
       "      <td>Instance 0</td>\n",
       "      <td>Batch 0</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.7277117562999531, 0.916822078309722, 0.930...</td>\n",
       "      <td>641.426558</td>\n",
       "      <td>0.324159</td>\n",
       "      <td>4.954856</td>\n",
       "      <td>0.083221</td>\n",
       "      <td>0.094052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.047251</td>\n",
       "      <td>-0.107175</td>\n",
       "      <td>-0.032991</td>\n",
       "      <td>-0.058021</td>\n",
       "      <td>-0.042201</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>-0.021313</td>\n",
       "      <td>-1.221870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Type 0</td>\n",
       "      <td>Instance 0</td>\n",
       "      <td>Batch 1</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.7632954709436864, 1.026018785736818, 0.992...</td>\n",
       "      <td>645.520956</td>\n",
       "      <td>0.337653</td>\n",
       "      <td>5.051188</td>\n",
       "      <td>0.087290</td>\n",
       "      <td>0.105254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>-0.007687</td>\n",
       "      <td>-0.057737</td>\n",
       "      <td>-0.008522</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>-0.114816</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>-0.033735</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>-1.151329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Type 0</td>\n",
       "      <td>Instance 0</td>\n",
       "      <td>Batch 2</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.6994250167326957, 1.0291789906086368, 1.00...</td>\n",
       "      <td>645.265557</td>\n",
       "      <td>0.303135</td>\n",
       "      <td>5.219517</td>\n",
       "      <td>0.079986</td>\n",
       "      <td>0.105578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046989</td>\n",
       "      <td>-0.050062</td>\n",
       "      <td>-0.058246</td>\n",
       "      <td>-0.004238</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>-0.020454</td>\n",
       "      <td>-0.039416</td>\n",
       "      <td>-0.067475</td>\n",
       "      <td>0.055180</td>\n",
       "      <td>-1.142082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Type 0</td>\n",
       "      <td>Instance 0</td>\n",
       "      <td>Batch 3</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.7197691024953152, 0.9805081083806637, 1.08...</td>\n",
       "      <td>638.926732</td>\n",
       "      <td>0.326678</td>\n",
       "      <td>4.897391</td>\n",
       "      <td>0.082312</td>\n",
       "      <td>0.100585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069115</td>\n",
       "      <td>-0.084675</td>\n",
       "      <td>-0.044433</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>-0.079871</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.093729</td>\n",
       "      <td>-1.195320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Type 0</td>\n",
       "      <td>Instance 0</td>\n",
       "      <td>Batch 4</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.7628378021730651, 1.0083804119903377, 0.93...</td>\n",
       "      <td>647.660678</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>5.133511</td>\n",
       "      <td>0.087238</td>\n",
       "      <td>0.103445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097047</td>\n",
       "      <td>-0.209941</td>\n",
       "      <td>-0.042993</td>\n",
       "      <td>-0.026468</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.036349</td>\n",
       "      <td>-0.046130</td>\n",
       "      <td>-0.084086</td>\n",
       "      <td>0.087641</td>\n",
       "      <td>-1.254962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Type 3</td>\n",
       "      <td>Instance 9</td>\n",
       "      <td>Batch 5</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.49659716029557777, 0.4425064350133267, 0.3...</td>\n",
       "      <td>1062.876245</td>\n",
       "      <td>0.789718</td>\n",
       "      <td>9.427059</td>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>-0.048245</td>\n",
       "      <td>-0.080472</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>-0.017658</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.022788</td>\n",
       "      <td>-0.065025</td>\n",
       "      <td>-0.506730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>Type 3</td>\n",
       "      <td>Instance 9</td>\n",
       "      <td>Batch 6</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.5043007155127691, 0.39774674648989383, 0.3...</td>\n",
       "      <td>1064.303519</td>\n",
       "      <td>0.733586</td>\n",
       "      <td>9.880854</td>\n",
       "      <td>0.035158</td>\n",
       "      <td>0.022351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.045567</td>\n",
       "      <td>-0.026982</td>\n",
       "      <td>-0.016895</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>0.077906</td>\n",
       "      <td>0.071395</td>\n",
       "      <td>-0.004335</td>\n",
       "      <td>-0.501006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>Type 3</td>\n",
       "      <td>Instance 9</td>\n",
       "      <td>Batch 7</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.5821150939298224, 0.4964565617228369, 0.44...</td>\n",
       "      <td>1049.298608</td>\n",
       "      <td>0.811217</td>\n",
       "      <td>9.406992</td>\n",
       "      <td>0.040583</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049042</td>\n",
       "      <td>-0.035306</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-0.496578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Type 3</td>\n",
       "      <td>Instance 9</td>\n",
       "      <td>Batch 8</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.5669225844487371, 0.6100229439430204, 0.16...</td>\n",
       "      <td>1061.280688</td>\n",
       "      <td>0.716930</td>\n",
       "      <td>9.790247</td>\n",
       "      <td>0.039524</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014869</td>\n",
       "      <td>-0.027454</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>-0.001653</td>\n",
       "      <td>-0.027823</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>-0.004834</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>-0.481380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Type 3</td>\n",
       "      <td>Instance 9</td>\n",
       "      <td>Batch 9</td>\n",
       "      <td>Standard Linear Regression</td>\n",
       "      <td>[[0.4887090586687676, 0.4013099402871284, 0.31...</td>\n",
       "      <td>1066.515198</td>\n",
       "      <td>0.824887</td>\n",
       "      <td>9.328169</td>\n",
       "      <td>0.034071</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.037616</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>-0.031840</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>0.022494</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>-0.468137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  1308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type nr Instance nr Batch nr                      Method  \\\n",
       "0     Type 0  Instance 0  Batch 0  Standard Linear Regression   \n",
       "3     Type 0  Instance 0  Batch 1  Standard Linear Regression   \n",
       "6     Type 0  Instance 0  Batch 2  Standard Linear Regression   \n",
       "9     Type 0  Instance 0  Batch 3  Standard Linear Regression   \n",
       "12    Type 0  Instance 0  Batch 4  Standard Linear Regression   \n",
       "...      ...         ...      ...                         ...   \n",
       "1185  Type 3  Instance 9  Batch 5  Standard Linear Regression   \n",
       "1188  Type 3  Instance 9  Batch 6  Standard Linear Regression   \n",
       "1191  Type 3  Instance 9  Batch 7  Standard Linear Regression   \n",
       "1194  Type 3  Instance 9  Batch 8  Standard Linear Regression   \n",
       "1197  Type 3  Instance 9  Batch 9  Standard Linear Regression   \n",
       "\n",
       "                                                   Beta  Error Prediction  \\\n",
       "0     [[0.7277117562999531, 0.916822078309722, 0.930...        641.426558   \n",
       "3     [[0.7632954709436864, 1.026018785736818, 0.992...        645.520956   \n",
       "6     [[0.6994250167326957, 1.0291789906086368, 1.00...        645.265557   \n",
       "9     [[0.7197691024953152, 0.9805081083806637, 1.08...        638.926732   \n",
       "12    [[0.7628378021730651, 1.0083804119903377, 0.93...        647.660678   \n",
       "...                                                 ...               ...   \n",
       "1185  [[0.49659716029557777, 0.4425064350133267, 0.3...       1062.876245   \n",
       "1188  [[0.5043007155127691, 0.39774674648989383, 0.3...       1064.303519   \n",
       "1191  [[0.5821150939298224, 0.4964565617228369, 0.44...       1049.298608   \n",
       "1194  [[0.5669225844487371, 0.6100229439430204, 0.16...       1061.280688   \n",
       "1197  [[0.4887090586687676, 0.4013099402871284, 0.31...       1066.515198   \n",
       "\n",
       "      Error Objective  Error Constraint  Contribution Target 0 Val\\n1  \\\n",
       "0            0.324159          4.954856                      0.083221   \n",
       "3            0.337653          5.051188                      0.087290   \n",
       "6            0.303135          5.219517                      0.079986   \n",
       "9            0.326678          4.897391                      0.082312   \n",
       "12           0.329613          5.133511                      0.087238   \n",
       "...               ...               ...                           ...   \n",
       "1185         0.789718          9.427059                      0.034621   \n",
       "1188         0.733586          9.880854                      0.035158   \n",
       "1191         0.811217          9.406992                      0.040583   \n",
       "1194         0.716930          9.790247                      0.039524   \n",
       "1197         0.824887          9.328169                      0.034071   \n",
       "\n",
       "      Contribution Target 0 Val\\n2  ...  Contribution Target 25 Wgt\\n16  \\\n",
       "0                         0.094052  ...                       -0.039456   \n",
       "3                         0.105254  ...                        0.008684   \n",
       "6                         0.105578  ...                       -0.046989   \n",
       "9                         0.100585  ...                       -0.069115   \n",
       "12                        0.103445  ...                        0.097047   \n",
       "...                            ...  ...                             ...   \n",
       "1185                      0.024866  ...                        0.023242   \n",
       "1188                      0.022351  ...                        0.000924   \n",
       "1191                      0.027898  ...                        0.049042   \n",
       "1194                      0.034280  ...                       -0.014869   \n",
       "1197                      0.022551  ...                        0.016593   \n",
       "\n",
       "      Contribution Target 25 Wgt\\n17  Contribution Target 25 Wgt\\n18  \\\n",
       "0                           0.047251                       -0.107175   \n",
       "3                          -0.007687                       -0.057737   \n",
       "6                          -0.050062                       -0.058246   \n",
       "9                          -0.084675                       -0.044433   \n",
       "12                         -0.209941                       -0.042993   \n",
       "...                              ...                             ...   \n",
       "1185                       -0.048245                       -0.080472   \n",
       "1188                        0.045567                       -0.026982   \n",
       "1191                       -0.035306                       -0.001722   \n",
       "1194                       -0.027454                        0.017063   \n",
       "1197                        0.037616                        0.005553   \n",
       "\n",
       "      Contribution Target 25 Wgt\\n19  Contribution Target 25 Wgt\\n20  \\\n",
       "0                          -0.032991                       -0.058021   \n",
       "3                          -0.008522                        0.030135   \n",
       "6                          -0.004238                        0.008884   \n",
       "9                           0.018582                       -0.079871   \n",
       "12                         -0.026468                        0.000608   \n",
       "...                              ...                             ...   \n",
       "1185                        0.002785                        0.002518   \n",
       "1188                       -0.016895                        0.002265   \n",
       "1191                        0.004710                        0.004954   \n",
       "1194                       -0.001653                       -0.027823   \n",
       "1197                       -0.031840                       -0.003191   \n",
       "\n",
       "      Contribution Target 25 Wgt\\n21  Contribution Target 25 Wgt\\n22  \\\n",
       "0                          -0.042201                        0.002343   \n",
       "3                          -0.114816                        0.008336   \n",
       "6                          -0.020454                       -0.039416   \n",
       "9                          -0.005295                        0.013701   \n",
       "12                          0.036349                       -0.046130   \n",
       "...                              ...                             ...   \n",
       "1185                       -0.017658                        0.015944   \n",
       "1188                       -0.004626                        0.077906   \n",
       "1191                        0.006627                        0.006181   \n",
       "1194                        0.022326                        0.035715   \n",
       "1197                        0.023267                        0.018372   \n",
       "\n",
       "      Contribution Target 25 Wgt\\n23  Contribution Target 25 Wgt\\n24  \\\n",
       "0                          -0.022526                       -0.021313   \n",
       "3                          -0.033735                        0.040701   \n",
       "6                          -0.067475                        0.055180   \n",
       "9                           0.000329                        0.093729   \n",
       "12                         -0.084086                        0.087641   \n",
       "...                              ...                             ...   \n",
       "1185                        0.022788                       -0.065025   \n",
       "1188                        0.071395                       -0.004335   \n",
       "1191                        0.053872                       -0.002025   \n",
       "1194                       -0.004834                        0.005354   \n",
       "1197                        0.022494                        0.025847   \n",
       "\n",
       "      Contribution Target 25 Wgt\\n25  \n",
       "0                          -1.221870  \n",
       "3                          -1.151329  \n",
       "6                          -1.142082  \n",
       "9                          -1.195320  \n",
       "12                         -1.254962  \n",
       "...                              ...  \n",
       "1185                       -0.506730  \n",
       "1188                       -0.501006  \n",
       "1191                       -0.496578  \n",
       "1194                       -0.481380  \n",
       "1197                       -0.468137  \n",
       "\n",
       "[400 rows x 1308 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trgs = ['Contribution Target ' + str(i) for i in range(nr_trgts)]\n",
    "ftrs = np.concatenate((['Val\\n' + str(i+1) for i in range(nr_items)],['Wgt\\n' + str(i+1) for i in range(nr_items)]))\n",
    "print(trgs)\n",
    "\n",
    "# Create dataframe to plot stability boxplots later on\n",
    "df = pd.DataFrame.from_dict({(i,j,k,l): ins_dict[i][j][k][l]\n",
    "                                for i in ins_dict.keys()\n",
    "                                for j in ins_dict[i].keys()\n",
    "                                for k in ['Batch '+ str(l) for l in range(rsmpl_sz)]\n",
    "                                for l in dict_methods[i][j].keys()},\n",
    "                            orient='index'\n",
    "                            )\n",
    "df.index.names = ['Type nr', 'Instance nr','Batch nr', 'Method']\n",
    "df = df.reset_index()\n",
    "\n",
    "df_lists = df\n",
    "\n",
    "ftr_cols = []\n",
    "for trg in trgs:\n",
    "    trg_cols = np.concatenate(([trg + ' Val\\n' + str(i+1) for i in range(nr_items)],[trg + ' Wgt\\n' + str(i+1) for i in range(nr_items)]))\n",
    "    ftr_cols = np.concatenate((ftr_cols,trg_cols))\n",
    "    #split column of lists into new columns\n",
    "    split = pd.DataFrame(df[trg].to_list(), columns = trg_cols)\n",
    "    #join split columns back to original DataFrame\n",
    "    df = pd.concat([df, split], axis=1) \n",
    "    #drop original column\n",
    "    df = df.drop(trg, axis=1)\n",
    "# explode_lst = list(trgs) + ['Features']\n",
    "# df = df.explode(explode_lst, ignore_index=False)\n",
    "df.to_excel(\"Overview_Original_df_25_items\"+str(today)+\".xlsx\")  \n",
    "display(df[df['Method']=='Standard Linear Regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine % agreement over the x instances in the order of the first-k relative feature importance of Linear Regression surrogate\n",
    "def agreement(df_lcl, type, instance, method, target_index, total_batches = rsmpl_sz):\n",
    "    overlap       = []\n",
    "    srted_indices = []\n",
    "    ctoff_indices = []\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        df_tmp = df_lcl[(df_lcl['Type nr'] == type) & (df_lcl['Instance nr'] == instance) & (df_lcl['Method'] == method) & (df_lcl['Batch nr'] == 'Batch '+str(i))]\n",
    "        srtd_ind_btch = np.argsort(np.abs(df_tmp['Contribution Target ' +str(target_index)].iloc[0]))[::-1]\n",
    "        ctff_ind_btch = np.where(np.array(np.abs(df_tmp['Contribution Target ' +str(target_index)].iloc[0])) > epsilon)[0]\n",
    "        srted_indices.append(srtd_ind_btch)\n",
    "        ctoff_indices.append(ctff_ind_btch)\n",
    "\n",
    "    for i in range(1, len(srted_indices[0]) + 1):\n",
    "        ovrlp_cnt = 0\n",
    "        max_ovrlp = 0\n",
    "        for j1 in range(len(srted_indices)):\n",
    "            st1 = srted_indices[j1][:i]\n",
    "            co1 = ctoff_indices[j1]\n",
    "            sc1 = list(set(st1) & set(co1))\n",
    "            for j2 in range(j1+1, len(srted_indices)):\n",
    "                st2 = srted_indices[j2][:i]\n",
    "                co2 = ctoff_indices[j2]\n",
    "                sc2 = list(set(st2) & set(co2))\n",
    "                lcl_intrsctn  = list(set(sc1) & set(sc2))\n",
    "                ovrlp_cnt = ovrlp_cnt + len(lcl_intrsctn)\n",
    "                max_ovrlp = max_ovrlp + i\n",
    "        if max_ovrlp == 0:\n",
    "            overlap.append(1)\n",
    "        else:\n",
    "            overlap.append(ovrlp_cnt/max_ovrlp)\n",
    "    \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Standard Linear Regression', 'Decision Tree Regression', 'Regularized Linear Regression'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_methods['Type 0']['Instance 0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.742602060288277\n",
      "6.240664709792881\n",
      "30.6016301878197\n",
      "19.759575362592628\n",
      "4.470045994015143\n",
      "30.89313351527678\n",
      "25.821759690251593\n",
      "5.577092531882536\n",
      "30.86682602778583\n",
      "27.108044553620896\n",
      "5.664564814145605\n",
      "30.683578299837983\n",
      "19.212677621429187\n",
      "4.293612892674031\n",
      "30.48914746866275\n",
      "22.0335763771199\n",
      "4.490257146347481\n",
      "30.38524965928834\n",
      "21.933887947621233\n",
      "4.391497226779465\n",
      "30.23865812921907\n",
      "24.484807497875696\n",
      "4.913849930667229\n",
      "30.686271796294236\n",
      "24.24825347401201\n",
      "5.3928346569392165\n",
      "31.16184825862525\n",
      "20.547353808464525\n",
      "4.5579372806383835\n",
      "30.655095345329467\n",
      "32.36784393782383\n",
      "7.755825555890184\n",
      "31.223848335451066\n",
      "32.051986544238154\n",
      "7.453676842947754\n",
      "31.32349055372939\n",
      "31.01132539774322\n",
      "7.2656930248387575\n",
      "31.188287226813788\n",
      "31.364923055820313\n",
      "7.0638577381935015\n",
      "30.947861057511943\n",
      "33.06687751333445\n",
      "7.73881955363345\n",
      "31.666802651869684\n",
      "30.644055344732294\n",
      "7.273256708068701\n",
      "30.159570249275156\n",
      "31.392757684632947\n",
      "7.647718015553186\n",
      "30.970155772438982\n",
      "32.12841911978259\n",
      "7.000668033852978\n",
      "31.419173795796727\n",
      "32.92583427898155\n",
      "7.333232973883729\n",
      "31.99691894002867\n",
      "31.253774485773587\n",
      "7.02936489427783\n",
      "31.297179684515097\n",
      "32.00924957913946\n",
      "7.624360473979534\n",
      "30.644526448212453\n",
      "28.341627720546683\n",
      "6.4654953775997805\n",
      "30.3231195513919\n",
      "30.658015917977846\n",
      "6.825022492123368\n",
      "30.647420973627753\n",
      "31.3627411949314\n",
      "7.070222635048884\n",
      "30.734099056515106\n",
      "32.91847786116784\n",
      "7.546329214521488\n",
      "31.180329837865024\n",
      "29.986967208852946\n",
      "7.00736219669796\n",
      "30.613535764785993\n",
      "31.010537083422374\n",
      "7.2795824299322325\n",
      "30.666949496540685\n",
      "32.39953463669075\n",
      "6.771701410697726\n",
      "31.148037653380257\n",
      "32.78603454462411\n",
      "7.253604192577428\n",
      "31.420456255834832\n",
      "31.231029255894256\n",
      "7.110577329330493\n",
      "30.8598544681825\n",
      "32.10399100241626\n",
      "7.6577933354138645\n",
      "31.130721548736883\n",
      "28.437619029942542\n",
      "6.667152074774226\n",
      "30.40533119123338\n",
      "30.72745099791352\n",
      "7.24395244133119\n",
      "30.948215894891334\n",
      "31.556959966714523\n",
      "7.474195985164226\n",
      "31.11155708708664\n",
      "33.185693473176336\n",
      "7.862559120589125\n",
      "31.512394159785647\n",
      "30.36638826076112\n",
      "7.1980023996650395\n",
      "30.94993945975246\n",
      "31.050761603590924\n",
      "7.458203243524782\n",
      "30.927165858754623\n",
      "32.737993570482416\n",
      "7.448562292086432\n",
      "31.641818075361066\n",
      "32.42503477129862\n",
      "7.674466762363261\n",
      "31.714721622744563\n",
      "31.250924530299493\n",
      "7.266682027424772\n",
      "30.975248202296907\n"
     ]
    }
   ],
   "source": [
    "f = 5\n",
    "\n",
    "df['Agreement'] = np.nan\n",
    "df['Agreement top '+str(f)] = np.nan\n",
    "        \n",
    "for i in ins_dict.keys():\n",
    "    for j in ins_dict[i].keys():\n",
    "        for k in dict_methods[i][j].keys():\n",
    "            # print(i,j,k)\n",
    "            agrm_mthd = 0\n",
    "            agrm_mthd_f = 0\n",
    "            for t in range(nr_trgts):\n",
    "                lcl_agrm = agreement(df_lists, type=i, instance=j, method=k, target_index=t, total_batches= rsmpl_sz)\n",
    "                agrm_mthd   = agrm_mthd   + sum(lcl_agrm)\n",
    "                agrm_mthd_f = agrm_mthd_f + sum(lcl_agrm[:f])\n",
    "            print(float(agrm_mthd/nr_trgts))\n",
    "\n",
    "            df['Agreement'] = np.where((df['Type nr']==i) & (df['Instance nr']==j) & (df['Method']==k),float(agrm_mthd/nr_trgts), df['Agreement'])\n",
    "            df['Agreement top '+str(f)] = np.where((df['Type nr']==i) & (df['Instance nr']==j) & (df['Method']==k),float(agrm_mthd_f/nr_trgts), df['Agreement top '+str(f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "agg_dict = {'Error Prediction':'mean', 'Error Objective':'mean', 'Error Constraint':'mean', 'Agreement':'mean', 'Agreement top '+str(f):'mean'}\n",
    "for ftr in ftr_cols:\n",
    "    agg_dict[ftr] = ['mean', 'std']\n",
    "\n",
    "df_group = df.groupby(['Type nr', 'Method']).agg(agg_dict)\n",
    "\n",
    "top_cols_all = []\n",
    "for trg in trgs:\n",
    "    top_cols = [(trg, 'Top ' + str(i+1)) for i in range(f)]\n",
    "    micolumns = pd.MultiIndex.from_tuples(top_cols)\n",
    "    top_cols_all = np.concatenate((top_cols_all, micolumns))\n",
    "    slc_cols = [(trg + ' ' + ftr, 'mean') for ftr in ftrs]\n",
    "    tmp = df_group[slc_cols].apply(lambda x: np.absolute(x).nlargest(f).index.tolist(), axis=1).tolist()\n",
    "    output = [[item[0] for item in lst] for lst in tmp]\n",
    "    df_group = df_group.join(pd.DataFrame(output, \n",
    "                           columns=micolumns, index=df_group.index))\n",
    "\n",
    "df_group[('Top '+str(f)+' contributors', '')] = df_group[top_cols_all].values.tolist()\n",
    "df_group = df_group.drop(columns=top_cols_all)\n",
    "\n",
    "ftr_sgn_lst = []\n",
    "ftr_std_lst = []\n",
    "ftr_nrm_std_lst = []\n",
    "for ftr in ftr_cols:\n",
    "    #Significant if mean contribution is larger than epsilon\n",
    "    df_group[(ftr, 'sign.')] = np.where(np.absolute(df_group[(ftr,'mean')].astype(float)) <= epsilon, 0, 1)\n",
    "    #In a top 5 contributor\n",
    "    df_group[(ftr, 'top '+str(f))] = df_group[('Top '+str(f)+' contributors', '')].apply(lambda lst: 1 if ftr in lst else 0)\n",
    "    #Index of dispersion\n",
    "    df_group[(ftr, 'Normalized std')] = np.where(df_group[(ftr, 'sign.')]==0, 0, np.absolute(df_group[(ftr, 'std')]/df_group[(ftr, 'mean')]))\n",
    "    \n",
    "    ftr_sgn_lst.append((ftr, 'sign.'))\n",
    "    ftr_std_lst.append((ftr, 'std'))\n",
    "    ftr_nrm_std_lst.append((ftr, 'Normalized std'))\n",
    "\n",
    "\n",
    "df_group['Avg. Normalized std'] = (sum(df_group[(i, 'sign.')]* df_group[(i, 'Normalized std')] for i in ftr_cols)/sum(df_group[(j, 'sign.')] for j in ftr_cols)).astype(float)\n",
    "df_group['Std. Normalized std'] = (sum(df_group[(i, 'sign.')]*(df_group[(i, 'Normalized std')] - df_group['Avg. Normalized std'])**2  for i in ftr_cols)/sum(df_group[(j, 'sign.')] for j in ftr_cols)).astype(float)\n",
    "df_group['Avg. std'] = (sum(df_group[(i, 'std')] for i in ftr_cols)/len(ftr_cols)).astype(float)\n",
    "df_group['Std. std'] = (sum((df_group[(i, 'std')] - df_group['Avg. std'])**2  for i in ftr_cols)/len(ftr_cols)).astype(float)\n",
    "\n",
    "\n",
    "df_group['Avg. Normalized std top '+str(f)] = (sum(df_group[(i, 'sign.')]*df_group[(i, 'top '+str(f))]*df_group[(i, 'Normalized std')] for i in ftr_cols)/sum(df_group[(j, 'sign.')]*df_group[(j, 'top '+str(f))] for j in ftr_cols)).astype(float)\n",
    "df_group['Std. Normalized std top '+str(f)] = (sum(df_group[(i, 'sign.')]*df_group[(i, 'top '+str(f))]*(df_group[(i, 'Normalized std')] - df_group['Avg. Normalized std top '+str(f)])**2  for i in ftr_cols)/sum(df_group[(j, 'sign.')]*df_group[(j, 'top '+str(f))] for j in ftr_cols)).astype(float)\n",
    "df_group['Avg. std top '+str(f)] = (sum(df_group[(i, 'sign.')]*df_group[(i, 'top '+str(f))]*df_group[(i, 'std')] for i in ftr_cols)/sum(df_group[(j, 'sign.')]*df_group[(j, 'top '+str(f))] for j in ftr_cols)).astype(float)\n",
    "df_group['Std. std top '+str(f)] = (sum(df_group[(i, 'sign.')]*df_group[(i, 'top '+str(f))]*(df_group[(i, 'std')] - df_group['Avg. std'])**2  for i in ftr_cols)/sum(df_group[(j, 'sign.')]*df_group[(j, 'top '+str(f))] for j in ftr_cols)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Error Prediction</th>\n",
       "      <th>Error Objective</th>\n",
       "      <th>Error Constraint</th>\n",
       "      <th>Avg. std</th>\n",
       "      <th>Std. std</th>\n",
       "      <th>Avg. Normalized std</th>\n",
       "      <th>Std. Normalized std</th>\n",
       "      <th>Avg. std top 5</th>\n",
       "      <th>Std. std top 5</th>\n",
       "      <th>Avg. Normalized std top 5</th>\n",
       "      <th>Std. Normalized std top 5</th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Agreement top 5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regression</th>\n",
       "      <td>893.373507</td>\n",
       "      <td>13.800736</td>\n",
       "      <td>37.736463</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>2.855253</td>\n",
       "      <td>10.630062</td>\n",
       "      <td>0.135511</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>2.521614</td>\n",
       "      <td>14.455971</td>\n",
       "      <td>7.395157</td>\n",
       "      <td>2.994487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized Linear Regression</th>\n",
       "      <td>1240.686027</td>\n",
       "      <td>0.267001</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.064030</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>2.877071</td>\n",
       "      <td>18.356301</td>\n",
       "      <td>0.157610</td>\n",
       "      <td>0.029367</td>\n",
       "      <td>0.768608</td>\n",
       "      <td>0.141918</td>\n",
       "      <td>31.131711</td>\n",
       "      <td>3.377201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Linear Regression</th>\n",
       "      <td>1110.585571</td>\n",
       "      <td>0.700378</td>\n",
       "      <td>8.937026</td>\n",
       "      <td>0.062956</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>1.701240</td>\n",
       "      <td>2.738628</td>\n",
       "      <td>0.176167</td>\n",
       "      <td>0.045077</td>\n",
       "      <td>0.663806</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>31.384282</td>\n",
       "      <td>3.306058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Error Prediction Error Objective  \\\n",
       "                                          mean            mean   \n",
       "Method                                                           \n",
       "Decision Tree Regression            893.373507       13.800736   \n",
       "Regularized Linear Regression      1240.686027        0.267001   \n",
       "Standard Linear Regression         1110.585571        0.700378   \n",
       "\n",
       "                              Error Constraint  Avg. std  Std. std  \\\n",
       "                                          mean                       \n",
       "Method                                                               \n",
       "Decision Tree Regression             37.736463  0.009389  0.001212   \n",
       "Regularized Linear Regression         0.031802  0.064030  0.003110   \n",
       "Standard Linear Regression            8.937026  0.062956  0.004720   \n",
       "\n",
       "                              Avg. Normalized std Std. Normalized std  \\\n",
       "                                                                        \n",
       "Method                                                                  \n",
       "Decision Tree Regression                 2.855253           10.630062   \n",
       "Regularized Linear Regression            2.877071           18.356301   \n",
       "Standard Linear Regression               1.701240            2.738628   \n",
       "\n",
       "                              Avg. std top 5 Std. std top 5  \\\n",
       "                                                              \n",
       "Method                                                        \n",
       "Decision Tree Regression            0.135511       0.019339   \n",
       "Regularized Linear Regression       0.157610       0.029367   \n",
       "Standard Linear Regression          0.176167       0.045077   \n",
       "\n",
       "                              Avg. Normalized std top 5  \\\n",
       "                                                          \n",
       "Method                                                    \n",
       "Decision Tree Regression                       2.521614   \n",
       "Regularized Linear Regression                  0.768608   \n",
       "Standard Linear Regression                     0.663806   \n",
       "\n",
       "                              Std. Normalized std top 5  Agreement  \\\n",
       "                                                              mean   \n",
       "Method                                                               \n",
       "Decision Tree Regression                      14.455971   7.395157   \n",
       "Regularized Linear Regression                  0.141918  31.131711   \n",
       "Standard Linear Regression                     0.093595  31.384282   \n",
       "\n",
       "                              Agreement top 5  \n",
       "                                         mean  \n",
       "Method                                         \n",
       "Decision Tree Regression             2.994487  \n",
       "Regularized Linear Regression        3.377201  \n",
       "Standard Linear Regression           3.306058  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_dsply = [('Error Prediction','mean'),('Error Objective','mean'), ('Error Constraint','mean'), ('Avg. std',''), ('Std. std',''), ('Avg. Normalized std',''), ('Std. Normalized std',''), ('Avg. std top 5',''), ('Std. std top 5',''), ('Avg. Normalized std top 5',''), ('Std. Normalized std top 5',''), ('Agreement','mean'), ('Agreement top 5','mean')]\n",
    "df_dsply = df_group[col_dsply]\n",
    "# display(df_dsply.loc['Type 0'].style.background_gradient(axis=0))\n",
    "display(df_dsply.loc['Type 3'])\n",
    "# df_dsply.to_excel(\"Overview_test_25_items\"+str(today)+\".xlsx\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
